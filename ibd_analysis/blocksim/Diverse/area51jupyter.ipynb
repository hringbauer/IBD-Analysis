{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Playground for trying stuff here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def post_process_IBD(IBD_blocks, spacing=0.05):\n",
    "    '''Post process IBD sharing. \n",
    "    Pool together IBD blocks that are less than \n",
    "    spacing cM apart. Update IBD block list'''\n",
    "\n",
    "    ibd_list=IBD_blocks\n",
    "    bl_list_final = [] # The pruned IBD List. Empty Container\n",
    "\n",
    "    print(\"Starting Post Processing!\")\n",
    "    start0 = timer()\n",
    "    # Update the End to absolute end of block:\n",
    "    ibd_list = [(x[0], x[0] + x[1], x[2], x[3], x[4]) for x in ibd_list]\n",
    "    k = len(ibd_list)\n",
    "\n",
    "    # Make List of geographic Position of Individuals. Sort them so that same pair of INDs always in the same order!\n",
    "    geo_inds = [min(x[2], x[3]) + max(x[2], x[3]) for x in ibd_list]    \n",
    "\n",
    "    def unique_rows(data):\n",
    "        '''Gives back unique rows in data and the indices needed to reconstruct the original thing'''\n",
    "        data = np.copy(data)  # Make copy to avoid GC getting stuck.\n",
    "        uniq, indices = np.unique(data.view(data.dtype.descr * data.shape[1]), return_inverse=True)\n",
    "        return np.copy(uniq.view(data.dtype).reshape(-1, data.shape[1])), np.copy(indices)  \n",
    "\n",
    "    _, inds = unique_rows(geo_inds)  # Extract \"unique\" Indices\n",
    "    nr_unique_prs = np.max(inds)+1     # The Nr of unique pairs (including 0)\n",
    "\n",
    "    bl_ls = [[] for _ in xrange(nr_unique_prs)] # List of Lists for IBD-Blocks\n",
    "\n",
    "    for i in xrange(len(inds)):\n",
    "        ind = inds[i] # Get Index\n",
    "        bl_ls[ind].append(ibd_list[i]) # Append the block to its unique Position.\n",
    "\n",
    "    def merge_blocks(block_ls, spacing):\n",
    "            '''Merge blocks between Individuals.\n",
    "            spacing: Maximal spacing of blocks to be fused.\n",
    "            block_ls: List of blocks - [[start, end, time]\n",
    "            I.: First detect all same pairs that share IBD and pool their blocks.\n",
    "            II.: Then merge these blocks if needed.'''\n",
    "            assert spacing >= 0  # Sanity Check\n",
    "    \n",
    "            block_ls.sort()  # Sort blocks by Start Point\n",
    "             \n",
    "            block_ls_final = []  # Empty Container for the final Block List\n",
    "            start, end, t = block_ls[0]  # Temporary Variables\n",
    "            \n",
    "            for bl in block_ls[1:]:\n",
    "                if (bl[0] - end) < spacing:  # If Overlap\n",
    "                    t = min(t, bl[2]) # Set time to minimum\n",
    "                    end = max(bl[1], end)  # Extend\n",
    "                    \n",
    "                else:\n",
    "                    block_ls_final.append((start, end, t))  # Append another Block\n",
    "                    start = bl[0]\n",
    "                    end = bl[1]\n",
    "                    t = bl[2]\n",
    "            block_ls_final.append((start, end, t))  # Append another Block\n",
    "            return block_ls_final\n",
    "        \n",
    "        \n",
    "    for blocks in bl_ls:\n",
    "        input_ls = [[x[0], x[1], x[4]] for x in blocks] # Extract list of block Starts and Ends.\n",
    "        blocks_final = merge_blocks(input_ls, spacing) # Do the Merging\n",
    "        bl=blocks[0]\n",
    "\n",
    "        for start, end, t in blocks_final:\n",
    "            bl_list_final.append((start, end, bl[2], bl[3], t)) \n",
    "\n",
    "\n",
    "    # Restore 2nd entry to relative length of block:\n",
    "    bl_list_final = [(x[0], x[1] - x[0], x[2], x[3], x[4]) for x in bl_list_final]\n",
    "    end = timer()\n",
    "    print(start)\n",
    "    print(end)\n",
    "    print(\"Time for Postprocessing: %.5f s\" % (end - start0))\n",
    "    print(\"Merged from %i to %i IBD blocks.\" % (k, len(bl_list_final)))\n",
    "    IBD_blocks = bl_list_final\n",
    "    return IBD_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.03, (3, 4), (2, 4), 6),\n",
       " (0.2, 0.5, (1, 1), (2, 2), 10),\n",
       " (0.15, 0.4, (2, 4), (3, 4), 9),\n",
       " (0.3, 0.6, (2, 4), (3, 4), 9)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ibd_list=[(0.1, 0.03, (3,4), (2,4), 6),(0.2, 0.5, (1,1), (2,2), 10),(0.15, 0.4, (2,4), (3,4), 9), (0.3, 0.6, (2,4), (3,4), 9)]\n",
    "fake_ibd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Post Processing!\n",
      "0.1\n",
      "1517845591.56\n",
      "Time for Postprocessing: 0.00061 s\n",
      "Merged from 4 to 2 IBD blocks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.2, 0.49999999999999994, (1, 1), (2, 2), 10),\n",
       " (0.1, 0.7999999999999999, (3, 4), (2, 4), 6)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_process_IBD(fake_ibd_list, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unique_rows(data):\n",
    "    '''Gives back unique rows in data and the indices needed to reconstruct the original thing'''\n",
    "    data = np.copy(data)  # Make copy to avoid GC getting stuck.\n",
    "    uniq, indices = np.unique(data.view(data.dtype.descr * data.shape[1]), return_inverse=True)\n",
    "    return np.copy(uniq.view(data.dtype).reshape(-1, data.shape[1])), np.copy(indices)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3, 3, 4), (3, 3, 3, 4), (2, 3, 3, 4)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=np.array([1,2,3])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.03, (3, 4), (2, 4), 6),\n",
       " (0.2, 0.5, (1, 1), (2, 2), 10),\n",
       " (0.15, 0.4, (2, 4), (3, 4), 9),\n",
       " (0.3, 0.6, (2, 4), (3, 4), 9)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=fake_ibd_list\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=None\n",
    "if a:\n",
    "    print(\"lul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
